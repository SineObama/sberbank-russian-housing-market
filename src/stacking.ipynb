{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn import ensemble   \n",
    "from sklearn import datasets   \n",
    "from sklearn.utils import shuffle   \n",
    "import xgboost as xgb\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "warn_log = True\n",
    "def logrmse(predictions, targets):\n",
    "    index = predictions > 0\n",
    "    if (not index.all()):\n",
    "        if (warn_log == True):\n",
    "            warn_log = False\n",
    "            print 'warning: not positive'\n",
    "    return rmse(np.log(predictions[index]), np.log(targets[index]))\n",
    "def xgblogrmse(predictions, dtrain):\n",
    "    return ('logrmse', logrmse(predictions, dtrain.get_label()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resolve():\n",
    "    ###  read the train, test and macro files\n",
    "    train_df = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
    "    test_df = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
    "    macro_df = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
    "    print(train_df.shape, test_df.shape)\n",
    "    \n",
    "    # combine macro information with train and test\n",
    "    train_df = pd.merge(train_df, macro_df, how='left', on='timestamp')\n",
    "    test_df = pd.merge(test_df, macro_df, how='left', on='timestamp')\n",
    "    print(train_df.shape, test_df.shape)\n",
    "    \n",
    "    # undersampling by magic numbers\n",
    "#     trainsub = train_df[train_df.timestamp < '2015-01-01']\n",
    "#     trainsub = trainsub[trainsub.product_type==\"Investment\"]\n",
    "#     ind_1m = trainsub[trainsub.price_doc <= 1000000].index\n",
    "#     ind_2m = trainsub[trainsub.price_doc == 2000000].index\n",
    "#     ind_3m = trainsub[trainsub.price_doc == 3000000].index\n",
    "#     train_index = set(train_df.index.copy())\n",
    "#     for ind, gap in zip([ind_1m, ind_2m, ind_3m], [10, 3, 2]):\n",
    "#         ind_set = set(ind)\n",
    "#         ind_set_cut = ind.difference(set(ind[::gap]))\n",
    "#         train_index = train_index.difference(ind_set_cut)\n",
    "        \n",
    "    ###  convert categorical variables into numerical variables by label encoding\n",
    "    objlist = []\n",
    "    for f in train_df.columns:\n",
    "        if train_df[f].dtype=='object':\n",
    "            objlist.append(f)       \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values.astype('str')) + list(test_df[f].values.astype('str')))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values.astype('str')))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values.astype('str')))\n",
    "            \n",
    "    # year and month #\n",
    "    train_df[\"yearmonth\"] = train_df[\"timestamp\"].dt.year*100 + train_df[\"timestamp\"].dt.month\n",
    "    test_df[\"yearmonth\"] = test_df[\"timestamp\"].dt.year*100 + test_df[\"timestamp\"].dt.month\n",
    "    # year and week #\n",
    "    train_df[\"yearweek\"] = train_df[\"timestamp\"].dt.year*100 + train_df[\"timestamp\"].dt.weekofyear\n",
    "    test_df[\"yearweek\"] = test_df[\"timestamp\"].dt.year*100 + test_df[\"timestamp\"].dt.weekofyear\n",
    "    # year #\n",
    "    train_df[\"year\"] = train_df[\"timestamp\"].dt.year\n",
    "    test_df[\"year\"] = test_df[\"timestamp\"].dt.year\n",
    "    # month of year #\n",
    "    train_df[\"month_of_year\"] = train_df[\"timestamp\"].dt.month\n",
    "    test_df[\"month_of_year\"] = test_df[\"timestamp\"].dt.month\n",
    "    # week of year #\n",
    "    train_df[\"week_of_year\"] = train_df[\"timestamp\"].dt.weekofyear\n",
    "    test_df[\"week_of_year\"] = test_df[\"timestamp\"].dt.weekofyear\n",
    "    # day of week #\n",
    "    train_df[\"day_of_week\"] = train_df[\"timestamp\"].dt.weekday\n",
    "    test_df[\"day_of_week\"] = test_df[\"timestamp\"].dt.weekday\n",
    "\n",
    "    ### We could potentially add more variables like this. But for now let us start with model building using these additional variables. Let us drop the variables which are not needed in model building.\n",
    "    train_X = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "    test_X = test_df.drop([\"id\", \"timestamp\"] , axis=1)\n",
    "    # Since our metric is \"RMSLE\", let us use log of the target variable for model building rather than using the actual target variable.\n",
    "    # train_y = np.log1p(train_df.price_doc.values)\n",
    "    train_y =(train_df.price_doc.values)\n",
    "    \n",
    "    return df_train['id'].values, train_X.values, train_y, test_X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bruno\n",
    "reload(bruno)\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "num_boost_rounds = 420  # From Bruno's original CV, I think\n",
    "bruno_xgb = XgbModel(xgb_params, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gunja\n",
    "reload(gunja)\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "num_boost_rounds = 422\n",
    "gunja_xgb = XgbModel(xgb_params, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import louis\n",
    "reload(louis)\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "num_boost_rounds = 385  # This was the CV output, as earlier version shows\n",
    "louis_xgb = XgbModel(xgb_params, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rfr\n",
    "reload(rfr)\n",
    "my_rfr = ensemble.RandomForestRegressor(n_estimators=70,max_depth=12)\n",
    "my_rfr = rfr.RfrModel(my_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "my_xgb = XgbModel(xgb_params, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../input/train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "               10,\n",
       "            ...\n",
       "            30464, 30465, 30466, 30467, 30468, 30469, 30470, 30471, 30472,\n",
       "            30473],\n",
       "           dtype='int64', name=u'id', length=30471)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 30471, 30472, 30473], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fx = pd.read_excel('../input/BAD_ADDRESS_FIX.xlsx').drop_duplicates('id').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.update(fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "id_train = df_train['id'].values\n",
    "y = df_train['price_doc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stacking' from 'stacking.pyc'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stacking import *\n",
    "import stacking\n",
    "reload(stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataResolver(object):\n",
    "    def __init__(self):\n",
    "        self.__time = -1\n",
    "    \n",
    "    def next(self):\n",
    "        self.__time = self.__time + 1\n",
    "        if (self.__time >= 1):\n",
    "            return resolve()\n",
    "        return rfr.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_models = []\n",
    "base_models.append(my_rfr)\n",
    "base_models.append(my_xgb)\n",
    "# base_models.append(bruno_xgb)\n",
    "# base_models.append(gunja_xgb)\n",
    "# base_models.append(louis_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacking = Stacking(3, base_models, DataResolver(), logrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((30471, 292), (7662, 291))\n",
      "((30471, 391), (7662, 390))\n",
      "model 0 fold 0\n",
      "train: 0.387185662396 val: 0.46317713979\n",
      "model 0 fold 1\n",
      "train: 0.385543231084 val: 0.482501056009\n",
      "model 0 fold 2\n",
      "train: 0.385960219561 val: 0.472786824998\n",
      "((30471, 292), (7662, 291))\n",
      "((30471, 391), (7662, 390))\n",
      "model 1 fold 0\n",
      "[0]\ttrain-rmse:8.24322e+06\tval-rmse:8.1257e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.49225e+06\tval-rmse:2.81501e+06\n",
      "[100]\ttrain-rmse:2.15807e+06\tval-rmse:2.6445e+06\n",
      "[150]\ttrain-rmse:2.03816e+06\tval-rmse:2.60676e+06\n",
      "[200]\ttrain-rmse:1.94939e+06\tval-rmse:2.59428e+06\n",
      "[250]\ttrain-rmse:1.87826e+06\tval-rmse:2.58575e+06\n",
      "[300]\ttrain-rmse:1.81294e+06\tval-rmse:2.57893e+06\n",
      "[350]\ttrain-rmse:1.74812e+06\tval-rmse:2.57286e+06\n",
      "[400]\ttrain-rmse:1.69398e+06\tval-rmse:2.57037e+06\n",
      "[450]\ttrain-rmse:1.6413e+06\tval-rmse:2.56727e+06\n",
      "[499]\ttrain-rmse:1.59814e+06\tval-rmse:2.56574e+06\n",
      "train: 0.404648279097 val: 0.45891762556\n",
      "model 1 fold 1\n",
      "[0]\ttrain-rmse:8.2102e+06\tval-rmse:8.2029e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.51994e+06\tval-rmse:2.85904e+06\n",
      "[100]\ttrain-rmse:2.17727e+06\tval-rmse:2.67403e+06\n",
      "[150]\ttrain-rmse:2.03928e+06\tval-rmse:2.63567e+06\n",
      "[200]\ttrain-rmse:1.94213e+06\tval-rmse:2.61111e+06\n",
      "[250]\ttrain-rmse:1.86829e+06\tval-rmse:2.59682e+06\n",
      "[300]\ttrain-rmse:1.80825e+06\tval-rmse:2.58927e+06\n",
      "[350]\ttrain-rmse:1.74764e+06\tval-rmse:2.58527e+06\n",
      "[400]\ttrain-rmse:1.68904e+06\tval-rmse:2.57942e+06\n",
      "[450]\ttrain-rmse:1.63656e+06\tval-rmse:2.57662e+06\n",
      "Stopping. Best iteration:\n",
      "[459]\ttrain-rmse:1.62763e+06\tval-rmse:2.57629e+06\n",
      "\n",
      "train: 0.400357486702 val: 0.474863087379\n",
      "model 1 fold 2\n",
      "[0]\ttrain-rmse:8.16471e+06\tval-rmse:8.29999e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.50557e+06\tval-rmse:2.9726e+06\n",
      "[100]\ttrain-rmse:2.16593e+06\tval-rmse:2.78472e+06\n",
      "[150]\ttrain-rmse:2.03561e+06\tval-rmse:2.74829e+06\n",
      "[200]\ttrain-rmse:1.94782e+06\tval-rmse:2.7267e+06\n",
      "[250]\ttrain-rmse:1.87529e+06\tval-rmse:2.72257e+06\n",
      "Stopping. Best iteration:\n",
      "[244]\ttrain-rmse:1.88316e+06\tval-rmse:2.72086e+06\n",
      "\n",
      "train: 0.432516451178 val: 0.469630393126\n"
     ]
    }
   ],
   "source": [
    "s_train, s_test = stacking.fit(id_train, 7662)#38132 30471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(s_train).to_csv('../stacking/rfr_xgb/3_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(s_test).to_csv('../stacking/rfr_xgb/3_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5850000,  6000000,  5700000, ...,  6970959, 13500000,  5600000], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4762740.70477522,   4609924.5       ],\n",
       "       [  4998582.42053592,   5416123.        ],\n",
       "       [  5204945.16485092,   4926099.        ],\n",
       "       ..., \n",
       "       [  5437575.43828289,   5570410.        ],\n",
       "       [ 10072001.69092676,  10696752.        ],\n",
       "       [  6189967.06682039,   5869192.5       ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5463892.23383271,  5537997.        ],\n",
       "       [ 8476058.39433344,  8675585.33333333],\n",
       "       [ 5915374.29501199,  5610116.5       ],\n",
       "       ..., \n",
       "       [ 4553765.13804639,  4516005.83333333],\n",
       "       [ 5584019.3606476 ,  5397009.33333333],\n",
       "       [ 8616919.26055608,  8457699.66666667]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.19094e+06\n",
      "[20]\ttrain-rmse:3.77798e+06\n",
      "[40]\ttrain-rmse:2.6509e+06\n",
      "[60]\ttrain-rmse:2.41604e+06\n",
      "[80]\ttrain-rmse:2.35392e+06\n",
      "[100]\ttrain-rmse:2.31773e+06\n",
      "[120]\ttrain-rmse:2.28764e+06\n",
      "[140]\ttrain-rmse:2.26144e+06\n",
      "[160]\ttrain-rmse:2.236e+06\n",
      "[180]\ttrain-rmse:2.21765e+06\n",
      "[200]\ttrain-rmse:2.1995e+06\n",
      "[220]\ttrain-rmse:2.18339e+06\n",
      "[240]\ttrain-rmse:2.16741e+06\n",
      "[260]\ttrain-rmse:2.15331e+06\n",
      "[280]\ttrain-rmse:2.13959e+06\n",
      "[300]\ttrain-rmse:2.12722e+06\n",
      "[320]\ttrain-rmse:2.11218e+06\n",
      "[340]\ttrain-rmse:2.09904e+06\n",
      "[360]\ttrain-rmse:2.08584e+06\n",
      "[380]\ttrain-rmse:2.0745e+06\n",
      "[399]\ttrain-rmse:2.06176e+06\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(s_train, y)\n",
    "#dtrain = xgb.DMatrix(s_train[:25000], y[:25000])\n",
    "dval = xgb.DMatrix(s_train[25000:], y[25000:])\n",
    "dtest = xgb.DMatrix(s_test)\n",
    "\n",
    "\n",
    "num_boost_rounds = 1000\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=400, evals={(dtrain,'train')}, verbose_eval=20)\n",
    "# model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds, evals=[(dtrain,'train'), (dval,'val')], early_stopping_rounds=20, verbose_eval=20)\n",
    "\n",
    "y_predict = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/test.csv')\n",
    "id_test = df_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacking_output = pd.DataFrame({'id': id_test, 'price_doc': y_predict })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacking_output.to_csv('../stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
