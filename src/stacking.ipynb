{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn import ensemble   \n",
    "from sklearn import datasets   \n",
    "from sklearn.utils import shuffle   \n",
    "import xgboost as xgb\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "warn_log = True\n",
    "def logrmse(predictions, targets):\n",
    "    index = predictions > 0\n",
    "    if (not index.all()):\n",
    "        if (warn_log == True):\n",
    "            warn_log = False\n",
    "            print 'warning: not positive'\n",
    "    return rmse(np.log(predictions[index]), np.log(targets[index]))\n",
    "def xgblogrmse(predictions, dtrain):\n",
    "    return ('logrmse', logrmse(predictions, dtrain.get_label()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resolve():\n",
    "    ###  read the train, test and macro files\n",
    "    train_df = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
    "    test_df = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
    "#     macro_df = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
    "#     print(train_df.shape, test_df.shape)\n",
    "    \n",
    "#     # combine macro information with train and test\n",
    "#     train_df = pd.merge(train_df, macro_df, how='left', on='timestamp')\n",
    "#     test_df = pd.merge(test_df, macro_df, how='left', on='timestamp')\n",
    "#     print(train_df.shape, test_df.shape)\n",
    "    \n",
    "    # undersampling by magic numbers\n",
    "#     trainsub = train_df[train_df.timestamp < '2015-01-01']\n",
    "#     trainsub = trainsub[trainsub.product_type==\"Investment\"]\n",
    "#     ind_1m = trainsub[trainsub.price_doc <= 1000000].index\n",
    "#     ind_2m = trainsub[trainsub.price_doc == 2000000].index\n",
    "#     ind_3m = trainsub[trainsub.price_doc == 3000000].index\n",
    "#     train_index = set(train_df.index.copy())\n",
    "#     for ind, gap in zip([ind_1m, ind_2m, ind_3m], [10, 3, 2]):\n",
    "#         ind_set = set(ind)\n",
    "#         ind_set_cut = ind.difference(set(ind[::gap]))\n",
    "#         train_index = train_index.difference(ind_set_cut)\n",
    "        \n",
    "    ###  convert categorical variables into numerical variables by label encoding\n",
    "    objlist = []\n",
    "    for f in train_df.columns:\n",
    "        if train_df[f].dtype=='object':\n",
    "            objlist.append(f)       \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values.astype('str')) + list(test_df[f].values.astype('str')))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values.astype('str')))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values.astype('str')))\n",
    "            \n",
    "    # year and month #\n",
    "    train_df[\"yearmonth\"] = train_df[\"timestamp\"].dt.year*100 + train_df[\"timestamp\"].dt.month\n",
    "    test_df[\"yearmonth\"] = test_df[\"timestamp\"].dt.year*100 + test_df[\"timestamp\"].dt.month\n",
    "    # year and week #\n",
    "    train_df[\"yearweek\"] = train_df[\"timestamp\"].dt.year*100 + train_df[\"timestamp\"].dt.weekofyear\n",
    "    test_df[\"yearweek\"] = test_df[\"timestamp\"].dt.year*100 + test_df[\"timestamp\"].dt.weekofyear\n",
    "    # year #\n",
    "    train_df[\"year\"] = train_df[\"timestamp\"].dt.year\n",
    "    test_df[\"year\"] = test_df[\"timestamp\"].dt.year\n",
    "    # month of year #\n",
    "    train_df[\"month_of_year\"] = train_df[\"timestamp\"].dt.month\n",
    "    test_df[\"month_of_year\"] = test_df[\"timestamp\"].dt.month\n",
    "    # week of year #\n",
    "    train_df[\"week_of_year\"] = train_df[\"timestamp\"].dt.weekofyear\n",
    "    test_df[\"week_of_year\"] = test_df[\"timestamp\"].dt.weekofyear\n",
    "    # day of week #\n",
    "    train_df[\"day_of_week\"] = train_df[\"timestamp\"].dt.weekday\n",
    "    test_df[\"day_of_week\"] = test_df[\"timestamp\"].dt.weekday\n",
    "\n",
    "    ### We could potentially add more variables like this. But for now let us start with model building using these additional variables. Let us drop the variables which are not needed in model building.\n",
    "    train_X = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "    test_X = test_df.drop([\"id\", \"timestamp\"] , axis=1)\n",
    "    # Since our metric is \"RMSLE\", let us use log of the target variable for model building rather than using the actual target variable.\n",
    "    # train_y = np.log1p(train_df.price_doc.values)\n",
    "    train_y =(train_df.price_doc.values)\n",
    "    \n",
    "    return df_train['id'].values, train_X.values, train_y, test_X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bruno\n",
    "reload(bruno)\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "num_boost_rounds = 420  # From Bruno's original CV, I think\n",
    "bruno_xgb = XgbModel(xgb_params, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gunja\n",
    "reload(gunja)\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "num_boost_rounds = 422\n",
    "gunja_xgb = XgbModel(xgb_params, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import louis\n",
    "reload(louis)\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "num_boost_rounds = 385  # This was the CV output, as earlier version shows\n",
    "louis_xgb = XgbModel(xgb_params, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rfr\n",
    "reload(rfr)\n",
    "my_rfr = ensemble.RandomForestRegressor(n_estimators=70,max_depth=12)\n",
    "my_rfr = rfr.RfrModel(my_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 0\n",
    "}\n",
    "my_xgb = XgbModel(xgb_params, 360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "id_train = df_train['id'].values\n",
    "y = df_train['price_doc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stacking' from 'stacking.pyc'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stacking import *\n",
    "import stacking\n",
    "reload(stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataResolver(object):\n",
    "    def __init__(self):\n",
    "        self.__time = -1\n",
    "    \n",
    "    def next(self):\n",
    "        self.__time = self.__time + 1\n",
    "        if (self.__time >= 1):\n",
    "            return resolve()\n",
    "        return rfr.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_models = []\n",
    "base_models.append(my_rfr)\n",
    "base_models.append(my_xgb)\n",
    "# base_models.append(bruno_xgb)\n",
    "# base_models.append(gunja_xgb)\n",
    "# base_models.append(louis_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacking = Stacking(5, base_models, DataResolver(), logrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 fold 0\n",
      "train: 0.390918680186 val: 0.474681384288\n",
      "model 0 fold 1\n",
      "train: 0.399627562681 val: 0.456041589892\n",
      "model 0 fold 2\n",
      "train: 0.392243549053 val: 0.488764661889\n",
      "model 0 fold 3\n",
      "train: 0.398487344793 val: 0.46300950829\n",
      "model 0 fold 4\n",
      "train: 0.390540030618 val: 0.477908705342\n",
      "model 1 fold 0\n",
      "[0]\ttrain-rmse:8.25762e+06\tval-rmse:8.06625e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.52012e+06\tval-rmse:2.9177e+06\n",
      "[100]\ttrain-rmse:2.19308e+06\tval-rmse:2.79422e+06\n",
      "[150]\ttrain-rmse:2.07142e+06\tval-rmse:2.76365e+06\n",
      "[200]\ttrain-rmse:1.98501e+06\tval-rmse:2.75784e+06\n",
      "[250]\ttrain-rmse:1.92054e+06\tval-rmse:2.74936e+06\n",
      "[300]\ttrain-rmse:1.86354e+06\tval-rmse:2.74207e+06\n",
      "[350]\ttrain-rmse:1.81199e+06\tval-rmse:2.73803e+06\n",
      "[359]\ttrain-rmse:1.80142e+06\tval-rmse:2.7369e+06\n",
      "train: 0.427851834006 val: 0.47056800432\n",
      "model 1 fold 1\n",
      "[0]\ttrain-rmse:8.20274e+06\tval-rmse:8.23046e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.57891e+06\tval-rmse:2.77706e+06\n",
      "[100]\ttrain-rmse:2.24532e+06\tval-rmse:2.53475e+06\n",
      "[150]\ttrain-rmse:2.12408e+06\tval-rmse:2.47034e+06\n",
      "[200]\ttrain-rmse:2.03677e+06\tval-rmse:2.44292e+06\n",
      "[250]\ttrain-rmse:1.95988e+06\tval-rmse:2.42191e+06\n",
      "[300]\ttrain-rmse:1.89894e+06\tval-rmse:2.40762e+06\n",
      "[350]\ttrain-rmse:1.83476e+06\tval-rmse:2.39305e+06\n",
      "[359]\ttrain-rmse:1.82766e+06\tval-rmse:2.39201e+06\n",
      "train: 0.43159459317 val: 0.451399900099\n",
      "model 1 fold 2\n",
      "[0]\ttrain-rmse:8.21577e+06\tval-rmse:8.16927e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.54994e+06\tval-rmse:2.8795e+06\n",
      "[100]\ttrain-rmse:2.2148e+06\tval-rmse:2.74078e+06\n",
      "[150]\ttrain-rmse:2.0777e+06\tval-rmse:2.70469e+06\n",
      "[200]\ttrain-rmse:1.98746e+06\tval-rmse:2.67907e+06\n",
      "[250]\ttrain-rmse:1.91535e+06\tval-rmse:2.67253e+06\n",
      "Stopping. Best iteration:\n",
      "[238]\ttrain-rmse:1.93092e+06\tval-rmse:2.67085e+06\n",
      "\n",
      "train: 0.435735251471 val: 0.484388509581\n",
      "model 1 fold 3\n",
      "[0]\ttrain-rmse:8.17053e+06\tval-rmse:8.35761e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.54971e+06\tval-rmse:2.90118e+06\n",
      "[100]\ttrain-rmse:2.21455e+06\tval-rmse:2.69101e+06\n",
      "[150]\ttrain-rmse:2.09716e+06\tval-rmse:2.64496e+06\n",
      "[200]\ttrain-rmse:2.00599e+06\tval-rmse:2.61738e+06\n",
      "[250]\ttrain-rmse:1.94e+06\tval-rmse:2.60679e+06\n",
      "[300]\ttrain-rmse:1.88038e+06\tval-rmse:2.59509e+06\n",
      "[350]\ttrain-rmse:1.82797e+06\tval-rmse:2.58688e+06\n",
      "Stopping. Best iteration:\n",
      "[337]\ttrain-rmse:1.84022e+06\tval-rmse:2.58461e+06\n",
      "\n",
      "train: 0.43128806012 val: 0.457326835021\n",
      "model 1 fold 4\n",
      "[0]\ttrain-rmse:8.19868e+06\tval-rmse:8.2435e+06\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:2.54129e+06\tval-rmse:2.98724e+06\n",
      "[100]\ttrain-rmse:2.19595e+06\tval-rmse:2.80539e+06\n",
      "[150]\ttrain-rmse:2.07638e+06\tval-rmse:2.77779e+06\n",
      "[200]\ttrain-rmse:1.99257e+06\tval-rmse:2.76606e+06\n",
      "[250]\ttrain-rmse:1.91578e+06\tval-rmse:2.74645e+06\n",
      "Stopping. Best iteration:\n",
      "[273]\ttrain-rmse:1.88653e+06\tval-rmse:2.74257e+06\n",
      "\n",
      "train: 0.433105796413 val: 0.474983242559\n"
     ]
    }
   ],
   "source": [
    "s_train, s_test = stacking.fit(id_train, 7662)#38132 30471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(s_train).to_csv('../stacking/rfr_xgb/5_timestamp_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(s_test).to_csv('../stacking/rfr_xgb/5_timestamp_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5850000,  6000000,  5700000, ...,  6970959, 13500000,  5600000], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5280882.8937919 ,   4887306.        ],\n",
       "       [  5304731.95568661,   5194107.        ],\n",
       "       [  5196958.60327571,   4406640.5       ],\n",
       "       ..., \n",
       "       [  5571862.36072391,   5603753.        ],\n",
       "       [  9755525.6443084 ,  11062858.        ],\n",
       "       [  6268209.89780055,   6383557.5       ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5449211.18650147,  5725944.        ],\n",
       "       [ 8490259.03188713,  8526298.8       ],\n",
       "       [ 5884816.00321119,  5800119.1       ],\n",
       "       ..., \n",
       "       [ 4479278.12520038,  5103306.8       ],\n",
       "       [ 5648953.38157603,  5672406.2       ],\n",
       "       [ 8691203.66496464,  8730989.9       ]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.19298e+06\n",
      "[50]\ttrain-rmse:2.48737e+06\n",
      "[100]\ttrain-rmse:2.31072e+06\n",
      "[150]\ttrain-rmse:2.23852e+06\n",
      "[200]\ttrain-rmse:2.18585e+06\n",
      "[250]\ttrain-rmse:2.14950e+06\n",
      "[300]\ttrain-rmse:2.11252e+06\n",
      "[350]\ttrain-rmse:2.07898e+06\n",
      "[400]\ttrain-rmse:2.04908e+06\n",
      "[450]\ttrain-rmse:2.02056e+06\n",
      "[499]\ttrain-rmse:1.99581e+06\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(s_train, y)\n",
    "#dtrain = xgb.DMatrix(s_train[:25000], y[:25000])\n",
    "dval = xgb.DMatrix(s_train[25000:], y[25000:])\n",
    "dtest = xgb.DMatrix(s_test)\n",
    "\n",
    "\n",
    "num_boost_rounds = 1000\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=500, evals={(dtrain,'train')}, verbose_eval=50)\n",
    "# model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds, evals=[(dtrain,'train'), (dval,'val')], early_stopping_rounds=20, verbose_eval=20)\n",
    "\n",
    "y_predict = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/test.csv')\n",
    "id_test = df_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacking_output = pd.DataFrame({'id': id_test, 'price_doc': y_predict })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacking_output.to_csv('../stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
